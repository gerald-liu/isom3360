{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Based Collaborative Filtering (Recommender Systems)\n",
    "\n",
    "#### Recommend movies to users\n",
    "\n",
    "This dataset describes 5-star rating from MovieLens, a movie recommendation service. It contains 100,836 ratings across 9,742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018. Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided. The data are contained in the files 'movies.csv' and 'ratings.csv'.\n",
    "\n",
    "In the collaborative filtering, the only information that we are using is ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libararies used for data management\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset 'movies.csv'\n",
    "\n",
    "movies = pd.read_csv('movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9742 entries, 0 to 9741\nData columns (total 3 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   movieId  9742 non-null   int64 \n 1   title    9742 non-null   object\n 2   genres   9742 non-null   object\ndtypes: int64(1), object(2)\nmemory usage: 228.5+ KB\n"
    }
   ],
   "source": [
    "# display the info on attributes\n",
    "\n",
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# display the first 5 records\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 100836 entries, 0 to 100835\nData columns (total 4 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   userId     100836 non-null  int64  \n 1   movieId    100836 non-null  int64  \n 2   rating     100836 non-null  float64\n 3   timestamp  100836 non-null  int64  \ndtypes: float64(1), int64(3)\nmemory usage: 3.1 MB\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   userId  movieId  rating  timestamp\n0       1        1     4.0  964982703\n1       1        3     4.0  964981247\n2       1        6     4.0  964982224\n3       1       47     5.0  964983815\n4       1       50     5.0  964982931",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>964981247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>964982224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>5.0</td>\n      <td>964983815</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>5.0</td>\n      <td>964982931</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# load the dataset 'ratings.csv'\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "ratings.info()\n",
    "\n",
    "# display the first 5 records\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map movie Id for movie name by join the table on 'movieId'\n",
    "user_movie_rating=pd.merge(ratings,movies,on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   userId  movieId  rating   timestamp             title  \\\n0       1        1     4.0   964982703  Toy Story (1995)   \n1       5        1     4.0   847434962  Toy Story (1995)   \n2       7        1     4.5  1106635946  Toy Story (1995)   \n3      15        1     2.5  1510577970  Toy Story (1995)   \n4      17        1     4.5  1305696483  Toy Story (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1  Adventure|Animation|Children|Comedy|Fantasy  \n2  Adventure|Animation|Children|Comedy|Fantasy  \n3  Adventure|Animation|Children|Comedy|Fantasy  \n4  Adventure|Animation|Children|Comedy|Fantasy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>847434962</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1106635946</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>1510577970</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>1</td>\n      <td>4.5</td>\n      <td>1305696483</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "user_movie_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a full table, rows: userIDs, and columns: movieIDs\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html\n",
    "M = user_movie_rating.pivot_table(index=['userId'],columns = ['title'],values = 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(610, 9719)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# get to know how many users and how many movies\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note this 9,719 is smaller than 9,742. Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python does not have built-in libarary for collaborative filtering. We need to do the calculation ourselves. We first define a function to calculate pearson correlation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate the Pearson correlation (similarity) between u1 and u2\n",
    "\n",
    "def pearson(u1, u2):\n",
    "    u1_dif = u1 - u1.mean()\n",
    "    u2_dif = u2 - u2.mean()\n",
    "    return np.sum(u1_dif*u2_dif)/np.sqrt(np.sum(u1_dif*u1_dif)*np.sum(u2_dif*u2_dif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0012645157377626514"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# show the pearson correlation between the first user and the second user in the data\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html\n",
    "# M.iloc[0,:] gives the rating info by first user, and M.iloc[1,:] gives the rating info by second user\n",
    "\n",
    "pearson(M.iloc[0,:], M.iloc[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, we define another function to find the k-nearest neighbors of a user, based on the similarity given by pearson correlation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the k-nearest neighbors\n",
    "def k_nearest_neighbors(user, k, M):\n",
    "    all_others = []\n",
    "    neighbors = []\n",
    "    \n",
    "    # M.shape[0] gives the total number of users/rows\n",
    "    for i in range(M.shape[0]):\n",
    "        # a user cannot be the neighbor of himself/herself, skip if so\n",
    "        if i == user:\n",
    "            continue\n",
    "        sim = pearson(M.iloc[user,:], M.iloc[i,:])\n",
    "        # skip if the similarity values is NaN\n",
    "        if np.isnan(sim):\n",
    "            continue\n",
    "        else:\n",
    "            # append the id and similarity score\n",
    "            all_others.append([i,sim])\n",
    "    \n",
    "    # reverse sort all the records based on the similarity score: highest value being the first\n",
    "    all_others.sort(key=lambda tup: tup[1], reverse = True) \n",
    "    \n",
    "    # select the top k neighbors \n",
    "    for i in range(k):\n",
    "        if i >= len(all_others):\n",
    "            break\n",
    "        neighbors.append(all_others[i])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we need to define a function to perform the prediction based on the ratings given by the k-nearest neighbors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform prediction/recommendation\n",
    "\n",
    "def predict(user, neighbors, M):\n",
    "    predictions = []\n",
    "\n",
    "    # for all the movies in the data, do the prediction\n",
    "    for i in range(M.shape[1]):\n",
    "        # if the rating given by the user is not missing, it means that the user has watched the movie. skip (no need to predict)\n",
    "        if ~np.isnan(M.iloc[user,i]):\n",
    "            continue\n",
    "        numerator = 0.0\n",
    "        denominator = 0.0\n",
    "        \n",
    "        # do the weighted average of the ratings given by the k-nearest neighbors, adjusting their rating bias.\n",
    "        for neighbor in neighbors:\n",
    "            neighbor_id = neighbor[0]\n",
    "            neighbor_sim = neighbor[1]\n",
    "            if np.isnan(M.iloc[neighbor_id,i]):\n",
    "                continue\n",
    "            numerator += neighbor_sim * (M.iloc[neighbor_id,i]-M.iloc[neighbor_id,:].mean())\n",
    "            denominator += np.abs(neighbor_sim)\n",
    "        if denominator == 0.0:\n",
    "               continue\n",
    "        pred_rating = numerator/denominator + M.iloc[user,:].mean() \n",
    "        predictions.append([i,pred_rating]) \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, we define a function to print the top-n recommendations to a user (those with the highest predicted ratings).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top n recommendations\n",
    "\n",
    "def top_n_recs(user, predictions, M, top_n):\n",
    "    \n",
    "    # sort the movies by predicted ratings, from the highest one to the lowest one\n",
    "    predictions.sort(key=lambda tup: tup[1], reverse = True) \n",
    "    \n",
    "    recommendations = []\n",
    "    for i in range(top_n):\n",
    "        if i >= len(predictions):\n",
    "            break\n",
    "        recommendations.append(predictions[i])\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"The top %d movies recommended to user %d are as follows:\" % (top_n, user+1))\n",
    "    j = 0\n",
    "    for rec in recommendations:\n",
    "        if j >= top_n:\n",
    "            break\n",
    "        print(\"Moive: %s, Predicted Rating:%.3f\" % (M.columns[rec[0]], rec[1])) \n",
    "        j = j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we define a function to combine the steps stated above. This gives the user-based collaborative filtering algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the user-based collaborative filtering algorithm\n",
    "def user_based_cf(user, M, k,top_n):\n",
    "    # first k-nearest neighbors\n",
    "    k_neighbors = k_nearest_neighbors(user, k, M)\n",
    "    # perform predictions for each movie not watched by the user\n",
    "    predictions = predict(user,k_neighbors, M)\n",
    "    # recommend the top n with highest predicted ratings\n",
    "    top_n_recs(user, predictions, M, top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For demonstration purpose, we also define a function to print the top n movies rated by the user. Here, n can be any number.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rating_records(user, M, highest_n):\n",
    "    records = []\n",
    "    for i in range(M.shape[1]):\n",
    "        if np.isnan(M.iloc[user,i]):\n",
    "            continue\n",
    "        records.append([M.columns[i],M.iloc[user,i]]) \n",
    "    records.sort(key=lambda tup: tup[1], reverse = True) \n",
    "    \n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"The top %d movies rated by user %d are as follows:\" % (highest_n, user+1))\n",
    "    j = 0\n",
    "    for record in records:\n",
    "        if j >= highest_n:\n",
    "            break\n",
    "        print(\"Moive: %s, Rating:%.3f\" % (record[0], record[1])) \n",
    "        j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore any warnings in calculation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we are ready to make recommendations to any user. Let's do it for user 11.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------------------------------------------------------\nThe top 20 movies rated by user 11 are as follows:\nMoive: Amistad (1997), Rating:5.000\nMoive: Apollo 13 (1995), Rating:5.000\nMoive: As Good as It Gets (1997), Rating:5.000\nMoive: Braveheart (1995), Rating:5.000\nMoive: Clear and Present Danger (1994), Rating:5.000\nMoive: Contact (1997), Rating:5.000\nMoive: Forrest Gump (1994), Rating:5.000\nMoive: Fugitive, The (1993), Rating:5.000\nMoive: Heat (1995), Rating:5.000\nMoive: Last of the Mohicans, The (1992), Rating:5.000\nMoive: Saving Private Ryan (1998), Rating:5.000\nMoive: Searching for Bobby Fischer (1993), Rating:5.000\nMoive: Silence of the Lambs, The (1991), Rating:5.000\nMoive: Titanic (1997), Rating:5.000\nMoive: Top Gun (1986), Rating:5.000\nMoive: Air Force One (1997), Rating:4.000\nMoive: Armageddon (1998), Rating:4.000\nMoive: Breakdown (1997), Rating:4.000\nMoive: Con Air (1997), Rating:4.000\nMoive: Conspiracy Theory (1997), Rating:4.000\n----------------------------------------------------------------\nThe top 10 movies recommended to user 11 are as follows:\nMoive: Usual Suspects, The (1995), Predicted Rating:5.616\nMoive: Jungle Book, The (1994), Predicted Rating:5.390\nMoive: Wallace & Gromit: A Close Shave (1995), Predicted Rating:5.390\nMoive: Wallace & Gromit: The Best of Aardman Animation (1996), Predicted Rating:5.390\nMoive: Strange Days (1995), Predicted Rating:5.196\nMoive: Leaving Las Vegas (1995), Predicted Rating:5.135\nMoive: French Kiss (1995), Predicted Rating:5.043\nMoive: Anna and the King (1999), Predicted Rating:4.911\nMoive: Back to the Future (1985), Predicted Rating:4.911\nMoive: Donnie Brasco (1997), Predicted Rating:4.911\n"
    }
   ],
   "source": [
    "# print the top 20 movies rated by user 11 (note: user 1 has the index 0)\n",
    "print_rating_records(10,M,20)\n",
    "# give 10 recommendations to user 11, with ratings predicted by the 10-nearest neighbors of user 11.\n",
    "user_based_cf(10, M, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Please feel free to change the user id, k (number of nearest neighbors used) above to see what results you can get.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Surprice package to do recommendation\n",
    "#### Surprise is an easy-to-use Python scikit for recommender systems.\n",
    "https://surprise.readthedocs.io/en/stable/index.html\n",
    "you will have to pip install 'scikit-surprise' in anaconda base terminal and Visual Studuio Code C++ build tools is needed\n",
    "https://code.visualstudio.com/docs/cpp/config-msvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs from surprise\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dataset ml-100k could not be found. Do you want to download it? [Y/n]Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\nDone! Dataset ml-100k has been saved to C:\\Users\\geral/.surprise_data/ml-100k\n"
    }
   ],
   "source": [
    "# load dataset for movie ratings\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define similarity function\n",
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0  # no shrinkage\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CF using KNNBasic\n",
    "CFalgo = KNNBasic(k=20,sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Estimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nEstimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nEstimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nEstimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nEstimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\nEvaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    1.0272  1.0132  1.0218  1.0079  1.0121  1.0164  0.0070  \nMAE (testset)     0.8118  0.8022  0.8065  0.7969  0.8015  0.8038  0.0050  \nFit time          3.05    2.93    2.77    2.87    2.72    2.87    0.12    \nTest time         3.98    3.96    3.78    4.07    3.65    3.89    0.15    \n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'test_rmse': array([1.02715128, 1.01318862, 1.02175359, 1.00787155, 1.01207923]),\n 'test_mae': array([0.81181125, 0.80224934, 0.80652996, 0.79692349, 0.80145297]),\n 'fit_time': (3.0542147159576416,\n  2.93269944190979,\n  2.7723522186279297,\n  2.8694632053375244,\n  2.719768762588501),\n 'test_time': (3.9833762645721436,\n  3.955451726913452,\n  3.7760236263275146,\n  4.073114395141602,\n  3.6541953086853027)}"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# cross validate the KNNBasic CF\n",
    "cross_validate(CFalgo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training set\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Estimating biases using als...\nComputing the pearson_baseline similarity matrix...\nDone computing similarity matrix.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<surprise.prediction_algorithms.knns.KNNBasic at 0x21ff8b6e908>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# fit the CFalgo with training set\n",
    "CFalgo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "user: 195        item: 302        r_ui = None   est = 4.17   {'actual_k': 20, 'was_impossible': False}\n"
    }
   ],
   "source": [
    "userid = str(195)  # raw user id (as in the ratings file). They are **strings**!\n",
    "movieid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = CFalgo.predict(userid, movieid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit ('py36': conda)",
   "language": "python",
   "name": "python36664bitpy36conda0373fbe9b8644b389824272c4174e4db"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}